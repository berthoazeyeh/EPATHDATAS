{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b1bc2fe",
    "outputId": "9432c469-3767-412f-a84e-e586c51ceda3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#Login to the user's google driver account\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0VVo3silxnw",
    "outputId": "419844b5-97b1-49b5-eb9c-3f74df22feff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
      "Executing: /tmp/apt-key-gpghome.0COGMktcfG/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9\n",
      "gpg: key 51716619E084DAB9: \"Michael Rutter <marutter@gmail.com>\" 1 new signature\n",
      "gpg: Total number processed: 1\n",
      "gpg:         new signatures: 1\n",
      "Repository: 'deb https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/'\n",
      "Description:\n",
      "Archive for codename: focal-cran40/ components: \n",
      "More info: https://cloud.r-project.org/bin/linux/ubuntu\n",
      "Adding repository.\n",
      "Press [ENTER] to continue or Ctrl-c to cancel.\n",
      "Adding deb entry to /etc/apt/sources.list.d/archive_uri-https_cloud_r-project_org_bin_linux_ubuntu-jammy.list\n",
      "Adding disabled deb-src entry to /etc/apt/sources.list.d/archive_uri-https_cloud_r-project_org_bin_linux_ubuntu-jammy.list\n",
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
      "Get:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
      "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [46.6 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
      "Get:6 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ Packages [90.3 kB]\n",
      "Hit:7 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
      "Get:9 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,186 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,455 kB]\n",
      "Hit:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,013 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,279 kB]\n",
      "Hit:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,419 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [49.8 kB]\n",
      "Hit:19 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Get:20 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,231 kB]\n",
      "Get:21 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,145 kB]\n",
      "Fetched 10.3 MB in 9s (1,173 kB/s)\n",
      "Reading package lists... Done\n",
      "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
      "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
      "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
      "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
      "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  r-base-core r-recommended\n",
      "Suggested packages:\n",
      "  elpa-ess r-doc-info | r-doc-pdf r-mathlib r-base-html\n",
      "Recommended packages:\n",
      "  r-base-html r-doc-html\n",
      "The following packages will be upgraded:\n",
      "  r-base r-base-core r-recommended\n",
      "3 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n",
      "Need to get 27.2 MB of archives.\n",
      "After this operation, 57.3 kB of additional disk space will be used.\n",
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ r-base-core 4.3.2-1.2204.0 [27.2 MB]\n",
      "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ r-base 4.3.2-1.2204.0 [46.4 kB]\n",
      "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ r-recommended 4.3.2-1.2204.0 [2,592 B]\n",
      "Fetched 27.2 MB in 2s (17.1 MB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "(Reading database ... 120874 files and directories currently installed.)\n",
      "Preparing to unpack .../r-base-core_4.3.2-1.2204.0_amd64.deb ...\n",
      "Unpacking r-base-core (4.3.2-1.2204.0) over (4.3.1-4.2204.0) ...\n",
      "Preparing to unpack .../r-base_4.3.2-1.2204.0_all.deb ...\n",
      "Unpacking r-base (4.3.2-1.2204.0) over (4.3.1-4.2204.0) ...\n",
      "Preparing to unpack .../r-recommended_4.3.2-1.2204.0_all.deb ...\n",
      "Unpacking r-recommended (4.3.2-1.2204.0) over (4.3.1-4.2204.0) ...\n",
      "Setting up r-base-core (4.3.2-1.2204.0) ...\n",
      "Installing new version of config file /etc/R/Makeconf ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Setting up r-recommended (4.3.2-1.2204.0) ...\n",
      "Setting up r-base (4.3.2-1.2204.0) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  codonw\n",
      "0 upgraded, 1 newly installed, 0 to remove and 31 not upgraded.\n",
      "Need to get 140 kB of archives.\n",
      "After this operation, 430 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 codonw amd64 1.4.4-6 [140 kB]\n",
      "Fetched 140 kB in 1s (119 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package codonw.\n",
      "(Reading database ... 120874 files and directories currently installed.)\n",
      "Preparing to unpack .../codonw_1.4.4-6_amd64.deb ...\n",
      "Unpacking codonw (1.4.4-6) ...\n",
      "Setting up codonw (1.4.4-6) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Installing packages into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "also installing the dependencies ‘pixmap’, ‘sp’, ‘Rcpp’, ‘RcppArmadillo’, ‘ade4’, ‘segmented’, ‘matrixStats’\n",
      "\n",
      "trying URL 'https://cran.rstudio.com/src/contrib/pixmap_0.4-12.tar.gz'\n",
      "Content type 'application/x-gzip' length 34637 bytes (33 KB)\n",
      "==================================================\n",
      "downloaded 33 KB\n",
      "\n",
      "trying URL 'https://cran.rstudio.com/src/contrib/sp_2.1-1.tar.gz'\n",
      "Content type 'application/x-gzip' length 1244612 bytes (1.2 MB)\n",
      "==================================================\n",
      "downloaded 1.2 MB\n",
      "\n",
      "trying URL 'https://cran.rstudio.com/src/contrib/Rcpp_1.0.11.tar.gz'\n",
      "Content type 'application/x-gzip' length 2994004 bytes (2.9 MB)\n",
      "==================================================\n",
      "downloaded 2.9 MB\n",
      "\n",
      "trying URL 'https://cran.rstudio.com/src/contrib/RcppArmadillo_0.12.6.6.0.tar.gz'\n",
      "Content type 'application/x-gzip' length 1403237 bytes (1.3 MB)\n",
      "==================================================\n",
      "downloaded 1.3 MB\n",
      "\n",
      "trying URL 'https://cran.rstudio.com/src/contrib/ade4_1.7-22.tar.gz'\n",
      "Content type 'application/x-gzip' length 3365194 bytes (3.2 MB)\n",
      "==================================================\n",
      "downloaded 3.2 MB\n",
      "\n",
      "trying URL 'https://cran.rstudio.com/src/contrib/segmented_1.6-4.tar.gz'\n",
      "Content type 'application/x-gzip' length 178319 bytes (174 KB)\n",
      "==================================================\n",
      "downloaded 174 KB\n",
      "\n",
      "trying URL 'https://cran.rstudio.com/src/contrib/matrixStats_1.0.0.tar.gz'\n",
      "Content type 'application/x-gzip' length 210653 bytes (205 KB)\n",
      "==================================================\n",
      "downloaded 205 KB\n",
      "\n",
      "trying URL 'https://cran.rstudio.com/src/contrib/protr_1.7-0.tar.gz'\n",
      "Content type 'application/x-gzip' length 1901580 bytes (1.8 MB)\n",
      "==================================================\n",
      "downloaded 1.8 MB\n",
      "\n",
      "trying URL 'https://cran.rstudio.com/src/contrib/rDNAse_1.1-1.tar.gz'\n",
      "Content type 'application/x-gzip' length 1290276 bytes (1.2 MB)\n",
      "==================================================\n",
      "downloaded 1.2 MB\n",
      "\n",
      "trying URL 'https://cran.rstudio.com/src/contrib/seqinr_4.2-30.tar.gz'\n",
      "Content type 'application/x-gzip' length 3538250 bytes (3.4 MB)\n",
      "==================================================\n",
      "downloaded 3.4 MB\n",
      "\n",
      "trying URL 'https://cran.rstudio.com/src/contrib/matrixTests_0.2.3.tar.gz'\n",
      "Content type 'application/x-gzip' length 79169 bytes (77 KB)\n",
      "==================================================\n",
      "downloaded 77 KB\n",
      "\n",
      "* installing *source* package ‘pixmap’ ...\n",
      "** package ‘pixmap’ successfully unpacked and MD5 sums checked\n",
      "** using staged installation\n",
      "** R\n",
      "** inst\n",
      "** byte-compile and prepare package for lazy loading\n",
      "** help\n",
      "*** installing help indices\n",
      "** building package indices\n",
      "** testing if installed package can be loaded from temporary location\n",
      "** testing if installed package can be loaded from final location\n",
      "** testing if installed package keeps a record of temporary installation path\n",
      "* DONE (pixmap)\n",
      "* installing *source* package ‘sp’ ...\n",
      "** package ‘sp’ successfully unpacked and MD5 sums checked\n",
      "** using staged installation\n",
      "** libs\n",
      "using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’\n",
      "gcc -I\"/usr/share/R/include\" -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-H0vbME/r-base-4.3.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c Rcentroid.c -o Rcentroid.o\n",
      "gcc -I\"/usr/share/R/include\" -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-H0vbME/r-base-4.3.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c gcdist.c -o gcdist.o\n",
      "gcc -I\"/usr/share/R/include\" -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-H0vbME/r-base-4.3.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c init.c -o init.o\n",
      "gcc -I\"/usr/share/R/include\" -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-H0vbME/r-base-4.3.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c pip.c -o pip.o\n",
      "gcc -I\"/usr/share/R/include\" -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-H0vbME/r-base-4.3.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c pip2.c -o pip2.o\n",
      "gcc -I\"/usr/share/R/include\" -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-H0vbME/r-base-4.3.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c sp_xports.c -o sp_xports.o\n",
      "gcc -I\"/usr/share/R/include\" -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-H0vbME/r-base-4.3.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c surfaceArea.c -o surfaceArea.o\n",
      "gcc -I\"/usr/share/R/include\" -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-H0vbME/r-base-4.3.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c zerodist.c -o zerodist.o\n",
      "gcc -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions -flto=auto -ffat-lto-objects -flto=auto -Wl,-z,relro -o sp.so Rcentroid.o gcdist.o init.o pip.o pip2.o sp_xports.o surfaceArea.o zerodist.o -L/usr/lib/R/lib -lR\n",
      "installing to /usr/local/lib/R/site-library/00LOCK-sp/00new/sp/libs\n",
      "** R\n",
      "** data\n",
      "** demo\n",
      "** inst\n",
      "** byte-compile and prepare package for lazy loading\n"
     ]
    }
   ],
   "source": [
    "#add the GPG key.\n",
    "# adding the secret key to the set of trusted keys\n",
    "!sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9\n",
    "#add repository\n",
    "# add r-project repository to apt repository\n",
    "!sudo add-apt-repository 'deb https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/'\n",
    "# update apt repository\n",
    "!sudo apt-get update\n",
    "#install R\n",
    "!sudo apt install r-base\n",
    "#install codonw\n",
    "!sudo apt-get install codonw\n",
    "#installation of required packages\n",
    "!echo \"install.packages(c('protr','rDNAse','seqinr','matrixTests'))\" > installPackages.R\n",
    "!Rscript installPackages.R\n",
    "#install biopython\n",
    "!pip install biopython\n",
    "!pip install rdkit\n",
    "!pip install -q condacolab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coIi3dHT5ClV"
   },
   "outputs": [],
   "source": [
    "#necessary dependencies\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import os\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import csv\n",
    "import condacolab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hI8P4RcN0ayU"
   },
   "outputs": [],
   "source": [
    "condacolab.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17zI8bkw0ot5"
   },
   "outputs": [],
   "source": [
    "#iFeature package\n",
    "!pip3 install iFeatureOmegaCLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ca5be3e6"
   },
   "outputs": [],
   "source": [
    "#organization code to process here\n",
    "organism_abbr = [\"dde\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0facdd2a"
   },
   "source": [
    "# Section in charge of the recovery of sequences in Kegg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "a8cc61a3",
    "outputId": "d0dd0d9b-0480-47ab-f394-a976cf936f85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'extract_feature_and_sequences'...\n",
      "remote: Enumerating objects: 283, done.\u001b[K\n",
      "remote: Counting objects: 100% (283/283), done.\u001b[K\n",
      "remote: Compressing objects: 100% (256/256), done.\u001b[K\n",
      "remote: Total 283 (delta 28), reused 275 (delta 25), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (283/283), 18.11 MiB | 28.02 MiB/s, done.\n",
      "Resolving deltas: 100% (28/28), done.\n",
      "/content/extract_feature_and_sequences\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'organism_abbr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3310c98c35c7>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'extract_feature_and_sequences/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#execution of the sequence extraction script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morganism_abbr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash extract_organism_sequence.sh {organism_abbr[i]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#Changing the current directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'organism_abbr' is not defined"
     ]
    }
   ],
   "source": [
    "#cloning of the gitlab repository which contains the script for retrieving the sequences\n",
    "!git clone https://gitlab.com/fofack/extract_feature_and_sequences.git\n",
    "#Changing the current directory\n",
    "%cd extract_feature_and_sequences/\n",
    "#execution of the sequence extraction script\n",
    "for i in range (len(organism_abbr)):\n",
    "  !bash extract_organism_sequence.sh {organism_abbr[i]}\n",
    "#Changing the current directory\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b1bed9d"
   },
   "source": [
    "# Section that contains the various functions useful for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4c4b72ef"
   },
   "outputs": [],
   "source": [
    "#function to retrieve the elements of a directory\n",
    "def find_dir( path_to_dir):\n",
    "    dirnames = listdir(path_to_dir)\n",
    "    return [ dirname for dirname in dirnames if dirname.endswith]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44badd03"
   },
   "outputs": [],
   "source": [
    "#function to retrieve fasta files from a directory\n",
    "def find_fasta_filenames( path_to_dir, suffix=\".fasta\" ):\n",
    "    filenames = listdir(path_to_dir)\n",
    "    return [ filename for filename in filenames if filename.endswith( suffix ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50f98c02"
   },
   "outputs": [],
   "source": [
    "#cleaning of gene sequences to remove sequences <=30 characters and descriptions in front of identifiers\n",
    "def parsing_sequence_dna(path_input, path_out):\n",
    "    with open(path_input) as handle:\n",
    "        with open(path_out, 'a') as clean_file:\n",
    "            for record in SeqIO.parse(handle, \"fasta\"):\n",
    "                if(len(record.seq) > 30):\n",
    "                    clean_file.write('>'+ \"%s\" %record.id[4:].upper()+'\\n')\n",
    "                    clean_file.write(\"%s\" %record.seq+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7c793441"
   },
   "outputs": [],
   "source": [
    "#cleanup of protein sequences to remove sequences <=30 characters and descriptions in front of identifiers\n",
    "def parsing_sequence_protein(path_input, path_out):\n",
    "    with open(path_input) as handle:\n",
    "        with open(path_out, 'a') as clean_file:\n",
    "            for record in SeqIO.parse(handle, \"fasta\"):\n",
    "                if(len(record.seq) > 30):\n",
    "                    clean_file.write('>'+ \"%s\" %record.id[4:].upper()+'\\n')\n",
    "                    clean_file.write(\"%s\" %record.seq+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20663b4a"
   },
   "outputs": [],
   "source": [
    "#cleaning of sequences with certain codons that do not correspond to any amino acid\n",
    "def delete_sequence_id(path_input, path_out,tab_id):\n",
    "    with open(path_input) as handle:\n",
    "        with open(path_out, 'a') as clean_file:\n",
    "            for record in SeqIO.parse(handle, \"fasta\"):\n",
    "                operator = record.id in tab_id\n",
    "                if(operator == False):\n",
    "                    clean_file.write('>'+ \"%s\" %record.id+'\\n')\n",
    "                    clean_file.write(\"%s\" %record.seq+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23cbc0e3"
   },
   "outputs": [],
   "source": [
    "#fusion of the two functions of cleaning gene and protein sequences\n",
    "def main_parsing_sequences(path_dir_input,path_dir_out):\n",
    "    path_data = find_fasta_filenames(path_dir_input)\n",
    "    for i in range(len(path_data)):\n",
    "        if(path_data[i] == \"dna_sequence.fasta\"):\n",
    "            print(path_dir_out+path_data[i])\n",
    "            parsing_sequence_dna(path_dir_input+path_data[i],path_dir_out+\"/\"+\"dna_sequence.fasta\")\n",
    "        else:\n",
    "            parsing_sequence_protein(path_dir_input+path_data[i],path_dir_out+\"/\"+\"protein_sequence.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5015f8f"
   },
   "outputs": [],
   "source": [
    "# function to retain only sequences that are in both genes and proteins\n",
    "def clean_sequences(gene_sequence, protein_sequence,path_out):\n",
    "    #load dataset\n",
    "    #aa\n",
    "    fastaSequences = SeqIO.parse(open(protein_sequence), 'fasta')\n",
    "    seqaaDict_E=dict()\n",
    "    for fasta in fastaSequences:\n",
    "        name, sequence = fasta.id, str(fasta.seq)\n",
    "        seqaaDict_E[name]=sequence\n",
    "    #print(seqaaDict_E)\n",
    "    #aa\n",
    "    fastaSequences = SeqIO.parse(open(gene_sequence), 'fasta')\n",
    "    seqntDict_E=dict()\n",
    "    for fasta in fastaSequences:\n",
    "        name, sequence = fasta.id, str(fasta.seq)\n",
    "        seqntDict_E[name]=sequence\n",
    "        #print(seqntDict_E)\n",
    "    index=0\n",
    "    fileSeqAA=open(path_out+\"EssentialsequenceAA-clean.fasta\", 'a')\n",
    "    fileSeqNT=open( path_out+\"EssentialsequenceNT-clean.fasta\", 'a')\n",
    "    for cle in seqntDict_E.keys():\n",
    "        if cle in seqaaDict_E:\n",
    "            #print(cle)\n",
    "            sequenceProt=seqaaDict_E[cle].upper()\n",
    "            sequenceGene=seqntDict_E[cle].upper()\n",
    "            gene_Locus=cle\n",
    "            recordAA=SeqRecord(Seq(sequenceProt), id=str(gene_Locus),description=\"\")\n",
    "            recordNT=SeqRecord(Seq(sequenceGene), id=str(gene_Locus),description=\"\")\n",
    "            SeqIO.write(recordAA, fileSeqAA, \"fasta\")\n",
    "            SeqIO.write(recordNT, fileSeqNT, \"fasta\")\n",
    "            index=index+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcc6abfb"
   },
   "outputs": [],
   "source": [
    "#function to transform an array of array into a simple array\n",
    "def transform_in_simple_array(tab):\n",
    "    probleme_codonw = []\n",
    "    p = re.compile(\"[A-Z]+[0-9]*[\\_]?[A-Z]*[0-9]+[\\_]?[0-9]*[\\-]?[A-Z]*[0-9]*\")\n",
    "    for i in range (len(tab)):\n",
    "        if(len(p.findall(tab[i]))):\n",
    "            probleme_codonw.append(p.findall(tab[i]))\n",
    "    id_probleme = np.array(probleme_codonw).flatten()\n",
    "    return id_probleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6donxd6upPcn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHbZx-g5pP8p"
   },
   "source": [
    "##Feature Methode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n037Yjx11Nfs"
   },
   "outputs": [],
   "source": [
    "import iFeatureOmegaCLI as iF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLh6KrZopVvE"
   },
   "outputs": [],
   "source": [
    "def get_feature_dna(path_input_sequence, path_out):\n",
    "    dna_descriptors = [\"NAC\",\"ANF\",\"ENAC\",\"MMI\",\"LPDF\",\"EIIP\",\"DPCP\",\"TPCP\",\n",
    "                       \"Kmer type 1\",\"RCKmer type 1\",\"PseEIIP\",\"PseKNC\",\n",
    "                       \"PCPseDNC\",\"PCPseTNC\",\"SCPseDNC\",\"SCPseTNC\",\"PSTNPss\",\n",
    "                       \"PSTNPds\",\"CKSNAP type 1\", \"DAC\",\"DACC\", \"DCC\", \"EGAAC\",\n",
    "                       \"TAC\", \"TACC\", \"TCC\",]\n",
    "    dna = iF.iDNA(path_input_sequence)\n",
    "    for i in range (len(dna_descriptors)):\n",
    "        dna.get_descriptor(dna_descriptors[i])\n",
    "        if(dna_descriptors[i] == \"Kmer type 1\"):\n",
    "          protein.to_csv(path_out+\"EssentialFeature_collection_\"+\"Kmer1\"+\".csv\",index=True, header=True)\n",
    "        elif (dna_descriptors[i] == \"RCKmer type 1\"):\n",
    "          protein.to_csv(path_out+\"EssentialFeature_collection_\"+\"RCKmer1\"+\".csv\",index=True, header=True)\n",
    "        elif (dna_descriptors[i] == \"CKSNAP type 1\"):\n",
    "          protein.to_csv(path_out+\"EssentialFeature_collection_\"+\"CKSNAP\"+\".csv\",index=True, header=True)\n",
    "        else:\n",
    "          dna.to_csv(path_out+\"EssentialFeature_collection_\"+dna_descriptors[i]+\".csv\",index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H76IdRugptPv"
   },
   "outputs": [],
   "source": [
    "def get_feature_peptide(path_file_sequence, path_out):\n",
    "    protein_descriptors = [\"CTDC\",\"CTDD\",\"CTDT\",\"DDE\",\"EGAAC\",\"GAAC\",\"AC\",\"CC\",\n",
    "                           \"ACC\",\"CKSAAP type 1\",\"KSCTriad\",\"DistancePair\",\n",
    "                           \"CKSAAGP type 1\",\"GDPC type 1\",\"GTPC type 1\",\"ASDC\",\n",
    "                           \"DPC type 1\",\"DPC type 2\",\"ZScale\", \"AAIndex\",\n",
    "                           \"TPC type 1\",\"TPC type 2\", \"ASDC\"]\n",
    "    protein = iF.iProtein(path_file_sequence)\n",
    "    for i in range (len(protein_descriptors)):\n",
    "      protein.get_descriptor(protein_descriptors[i])\n",
    "      if(protein_descriptors[i] == \"CKSAAP type 1\"):\n",
    "        protein.to_csv(path_out+\"EssentialFeature_collection_\"+\"CKSAAP\"+\".csv\",index=True, header=True)\n",
    "      elif (protein_descriptors[i] == \"DPC type 1\"):\n",
    "        protein.to_csv(path_out+\"EssentialFeature_collection_\"+\"DPC1\"+\".csv\",index=True, header=True)\n",
    "      elif (protein_descriptors[i] == \"DPC type 2\"):\n",
    "        protein.to_csv(path_out+\"EssentialFeature_collection_\"+\"DPC2\"+\".csv\",index=True, header=True)\n",
    "      elif (protein_descriptors[i] == \"TPC type 1\"):\n",
    "        protein.to_csv(path_out+\"EssentialFeature_collection_\"+\"TPC1\"+\".csv\",index=True, header=True)\n",
    "      elif (protein_descriptors[i] == \"TPC type 2\"):\n",
    "        protein.to_csv(path_out+\"EssentialFeature_collection_\"+\"TPC2\"+\".csv\",index=True, header=True)\n",
    "      elif (protein_descriptors[i] == \"GDPC type 1\"):\n",
    "        protein.to_csv(path_out+\"EssentialFeature_collection_\"+\"GDPC1\"+\".csv\",index=True, header=True)\n",
    "      elif (protein_descriptors[i] == \"GTPC type 1\"):\n",
    "        protein.to_csv(path_out+\"EssentialFeature_collection_\"+\"GTPC1\"+\".csv\",index=True, header=True)\n",
    "      else:\n",
    "        protein.to_csv(path_out+\"EssentialFeature_collection_\"+protein_descriptors[i]+\".csv\",index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ly3uvVlxptg_"
   },
   "outputs": [],
   "source": [
    "def main_iFeature(input_dna, out_dna, input_peptide, out_peptide):\n",
    "    get_feature_dna(input_dna, out_dna)\n",
    "    get_feature_peptide(input_peptide, out_peptide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrOX330xk8Pn"
   },
   "outputs": [],
   "source": [
    "def split_data(path_dir, path_out):\n",
    "    file = find_dir(path_dir)\n",
    "    #file.remove('.ipynb_checkpoints')\n",
    "    for i in range (len(file)):\n",
    "        print(file[i])\n",
    "        with open(path_dir+file[i],\"r\") as handle:\n",
    "            data = csv.reader(handle)\n",
    "            rows = [r for r in data]\n",
    "            rows[0].pop(0)\n",
    "            with open(path_out+file[i],\"w\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                for j in range(len(rows)):\n",
    "                    writer.writerow(rows[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93d8a34f"
   },
   "source": [
    "# Section responsible for feature extraction using R language packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9DvLIOgRg6R"
   },
   "outputs": [],
   "source": [
    "def main(path_input, path_out):\n",
    "    organism = find_dir(path_input)\n",
    "    for i in range (len(organism)):\n",
    "        print(\"################\"+\" \"+\"Feature de l'organisme\"+\" \"+organism[i]+\" \"+\"################\")\n",
    "        os.mkdir(path_out+organism[i])\n",
    "        os.mkdir(\"/content/results\"+organism[i])\n",
    "        main_parsing_sequences(path_input+organism[i]+\"/\", path_out+organism[i]+\"/\")\n",
    "        clean_sequences(path_out+organism[i]+\"/\"+\"dna_sequence.fasta\", path_out+organism[i]+\"/\"+\"protein_sequence.fasta\", path_out+organism[i]+\"/\")\n",
    "        chemin = path_out+organism[i]\n",
    "        pb = !codonw {chemin}/EssentialsequenceNT-clean.fasta results/{organism[i]}/EssentialcodonwFeature.out results/{organism[i]}/EssentialcodonwFeature.blk -nomenu -nowarn -all_indices -human\n",
    "        id_probleme = transform_in_simple_array(pb)\n",
    "        print(id_probleme)\n",
    "        if(len(id_probleme) > 0):\n",
    "            !mkdir clean_sequence_copy\n",
    "            !mkdir clean_sequence_copy/{organism[i]}\n",
    "            !mv /content/sequences_clean/{organism[i]}/dna_sequence.fasta clean_sequence_copy/{organism[i]}/\n",
    "            !mv /content/sequences_clean/{organism[i]}/protein_sequence.fasta clean_sequence_copy/{organism[i]}/\n",
    "            !rm /content/sequences_clean/{organism[i]}/EssentialsequenceNT-clean.fasta\n",
    "            !rm /content/sequences_clean/{organism[i]}/EssentialsequenceAA-clean.fasta\n",
    "            !rm /content/results/{organism[i]}/EssentialcodonwFeature.out\n",
    "            !rm /content/results/{organism[i]}/EssentialcodonwFeature.blk\n",
    "            delete_sequence_id(\"/content/clean_sequence_copy/\"+organism[i]+\"/\"+\"dna_sequence.fasta\", path_out+organism[i]+\"/\"+\"dna_sequence.fasta\", id_probleme)\n",
    "            delete_sequence_id(\"/content/clean_sequence_copy/\"+organism[i]+\"/\"+\"protein_sequence.fasta\", path_out+organism[i]+\"/\"+\"protein_sequence.fasta\", id_probleme)\n",
    "            clean_sequences(path_out+organism[i]+\"/\"+\"DNA_sequence.fasta\", path_out+organism[i]+\"/\"+\"protein_sequence.fasta\", path_out+organism[i]+\"/\")\n",
    "            chemin = path_out+organism[i]\n",
    "            pb1 =!codonw {chemin}/EssentialsequenceNT-clean.fasta results/{organism[i]}/EssentialcodonwFeature.out results/{organism[i]}/EssentialcodonwFeature.blk -nomenu -nowarn -all_indices -human\n",
    "            print(pb1)\n",
    "            print(\"************* Debut extraction des features de l'organisme\"+\" \"+organism[i] +\"**********\")\n",
    "            #extract sequence feature\n",
    "            !Rscript /content/extract_feature_and_sequences/gepoFeatureEngineering/scriptFeatureBySeq.R {path_out+organism[i]}/EssentialsequenceNT-clean.fasta {path_out+organism[i]}/EssentialsequenceAA-clean.fasta  /content/results/{organism[i]}/Essential\n",
    "            !rm /content/results/{organism[i]}/EssentialcodonwFeature.out\n",
    "            !rm /content/results/{organism[i]}/EssentialcodonwFeature.blk\n",
    "\n",
    "            #iFeature\n",
    "            mkdir /content/results_iFeat_tmp\n",
    "            main_iFeature('/content/sequences_clean/'+organism[i]+'/EssentialsequenceNT-clean.fasta','/content/results_iFeat_tmp/','/content/sequences_clean/'+organism[i]+'/EssentialsequenceAA-clean.fasta','/content/results_iFeat_tmp/')\n",
    "            split_data('/content/results_iFeat_tmp/', '/content/results/'+organism[i]+'/')\n",
    "            !sudo rm -r /content/results_iFeat_tmp\n",
    "\n",
    "            print(\"************* Fin extraction des features de l'organisme\"+\" \"+organism[i] +\"**********\")\n",
    "        else:\n",
    "            print(\"************* Debut extraction des features de l'organisme\"+\" \"+organism[i] +\"**********\")\n",
    "            #extract sequence feature\n",
    "            !Rscript /content/extract_feature_and_sequences/gepoFeatureEngineering/scriptFeatureBySeq.R {path_out+organism[i]}/EssentialsequenceNT-clean.fasta {path_out+organism[i]}/EssentialsequenceAA-clean.fasta /content/results/{organism[i]}/Essential\n",
    "\n",
    "            #iFeature\n",
    "            mkdir /content/results_iFeat_tmp\n",
    "            main_iFeature('/content/sequences_clean/'+organism[i]+'/EssentialsequenceNT-clean.fasta','/content/results_iFeat_tmp/','/content/sequences_clean/'+organism[i]+'/EssentialsequenceAA-clean.fasta','/content/results_iFeat_tmp/')\n",
    "            split_data('/content/results_iFeat_tmp/', '/content/results/'+organism[i]+'/')\n",
    "            !sudo rm -r /content/results_iFeat_tmp\n",
    "\n",
    "            !rm /content/results/{organism[i]}/EssentialcodonwFeature.out\n",
    "            !rm /content/results/{organism[i]}/EssentialcodonwFeature.blk\n",
    "            print(\"************* Fin extraction des features de l'organisme\"+\" \"+organism[i] +\"**********\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "154182db"
   },
   "source": [
    "# execution of the main function for the generation of the organism's features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4abfb29",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main(\"/content/extract_feature_and_sequences/organism/\", \"/content/sequences_clean/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6x7VskYoorW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5d29d81"
   },
   "source": [
    "# Dataset labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZ-Q-Xb6nbhi"
   },
   "outputs": [],
   "source": [
    "def main_labeling(epath_file, data_csv):\n",
    "    df = pd.read_csv(data_csv)\n",
    "    # Labelissage du dataset\n",
    "    df['essentiality'] = -1\n",
    "    id_kegg = df.index\n",
    "    epath = pd.read_excel(epath_file, sheet_name='Sheet1')\n",
    "    epath['Gene_Locus'] = epath['Gene_Locus'].str.upper()\n",
    "    epath.set_index(\"Gene_Locus\", inplace=True)\n",
    "    gene_locus = epath.index\n",
    "    for i in range (len(id_kegg)):\n",
    "        if(id_kegg[i] in np.array(gene_locus)):\n",
    "                df.at[id_kegg[i],'essentiality'] = epath.at[id_kegg[i],'Gene_essentaility']\n",
    "    df.drop(df[df.essentiality == -1].index, inplace=True)\n",
    "    mappings = {'NE': 0, 'E': 1}\n",
    "    classes = df.pop('essentiality')\n",
    "    essential_labels = classes.map(mappings)\n",
    "    df['essentiality_status'] = essential_labels\n",
    "    df = df.reset_index(drop=True)\n",
    "    features = df.columns[:-1]\n",
    "    target = [\"essentiality_status\"]\n",
    "    df_pr = preprocessing.normalize(df[features])\n",
    "    df_d = pd.DataFrame(df_pr, columns = features)\n",
    "    target_f = pd.DataFrame(df[\"essentiality_status\"], columns = target)\n",
    "    dataset_norm = pd.concat([df_d, target_f], axis=1)\n",
    "    return dataset_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "722e4671"
   },
   "outputs": [],
   "source": [
    "data_epath = find_dir(\"/content/extract_feature_and_sequences/Data_epath/\")\n",
    "for i in range (len(organism_abbr)):\n",
    "  !mkdir /content/{organism_abbr[i]}\n",
    "  for j in range (len(data_epath)):\n",
    "    if(organism_abbr[i] == data_epath[j].split(\"_\")[0]):\n",
    "      organism_data = find_dir(\"/content/results/\"+organism_abbr[i])\n",
    "      for item in range (len(organism_data)):\n",
    "        dataset = main_labeling(\"/content/extract_feature_and_sequences/Data_epath/\"+data_epath[j],\n",
    "                                \"/content/results/\"+organism_abbr[i]+\"/\"+organism_data[item])\n",
    "        subGroupName = organism_data[item].split(\"_\")[2].split(\".\")[0]\n",
    "        dataset.to_csv(organism_abbr[i]+\"/\"+subGroupName+\".csv\")\n",
    "        files.download(subGroupName+\".csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6e08f953",
    "outputId": "bdd97954-8787-4a30-dd01-5555eb9af04b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘dataLabels’: File exists\n",
      "fatal: destination path 'data' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!cd /content\n",
    "!mkdir dataLabels\n",
    "# !mkdir\n",
    "# !cd data\n",
    "!git clone https://gitlab.com/Berthoazeye/data.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHltpR9zO_qi",
    "outputId": "c4d46e9d-aeb7-4b80-855d-dfc89551cfb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4166"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "input_path = 'data/'\n",
    "output_path = 'dataLabels/'\n",
    "headers = ['Org','Gene_Locus','KO_Nb', 'Gene_Name', 'Gene_Function', 'E_Score','P_Score','Organism']\n",
    "\n",
    "len(os.listdir(input_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xTPZ9lLFUOkm"
   },
   "outputs": [],
   "source": [
    "def supprimer_extension(nom_fichier):\n",
    "    nom_base = os.path.basename(nom_fichier)\n",
    "    base, _ = os.path.splitext(nom_base)\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "o5DXGCKMPjWB",
    "outputId": "11f07d5f-4bac-418e-dc29-b080e9c500ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reste---------------------------------------------------------4166\n",
      "data/psn_Pseudopedobacter_saltans.csv\n",
      "reste---------------------------------------------------------4165\n",
      "data/duc_Dehalococcoides_sp._UCH007.csv\n",
      "reste---------------------------------------------------------4164\n",
      "data/mrd_Methylobacterium_radiotolerans.csv\n",
      "reste---------------------------------------------------------4163\n",
      "data/msb_Mycobacterium_smegmatis_MC2_155.csv\n",
      "reste---------------------------------------------------------4162\n",
      "data/bup_Buchnera_aphidicola_TLW03_Acyrthosiphon_pisum).csv\n",
      "/usr/bin/sh: 1: Syntax error: \")\" unexpected\n",
      "reste---------------------------------------------------------4162\n",
      "data/hpx_Helicobacter_pylori_83.csv\n",
      "reste---------------------------------------------------------4161\n",
      "data/ahd_Aeromonas_hydrophila_YL17.csv\n",
      "reste---------------------------------------------------------4160\n",
      "data/spht_Sphingobium_sp._TKS.csv\n",
      "reste---------------------------------------------------------4159\n",
      "data/zmn_Zymomonas_mobilis_subsp._mobilis_NCIMB_11163.csv\n",
      "reste---------------------------------------------------------4158\n",
      "data/mai_Micavibrio_aeruginosavorus_ARL-13.csv\n",
      "reste---------------------------------------------------------4157\n",
      "data/psi_Providencia_stuartii_MRSN_2154.csv\n",
      "reste---------------------------------------------------------4156\n",
      "data/btra_Bibersteinia_trehalosi_USDA-ARS-USMARC-190.csv\n",
      "reste---------------------------------------------------------4155\n",
      "data/acid_Acidovorax_sp_NA2.csv\n",
      "reste---------------------------------------------------------4154\n",
      "data/mef_Methanosarcina_sp._WH1.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(input_path):\n",
    "    print(\"reste---------------------------------------------------------\"+str(len(os.listdir(input_path))))\n",
    "    f = os.path.join(input_path, filename)\n",
    "    print(f)\n",
    "    if os.path.isfile(f):\n",
    "        file_csv = pd.read_csv(f)\n",
    "        for val in range(0,len(file_csv)):\n",
    "            # print(file_csv.loc[val,'E_Score'])\n",
    "            e_score = float(file_csv.loc[val,'E_Score'])\n",
    "            file_csv.replace(to_replace =\"9.16E-\",\n",
    "                 value = \"0.000\",\n",
    "                  inplace = True)\n",
    "            file_csv.replace(to_replace =\"4.28E-\",\n",
    "                 value = \"0.000\",\n",
    "                  inplace = True)\n",
    "            file_csv.replace(to_replace =\"3.47E-\",\n",
    "                 value = \"0.000\",\n",
    "                  inplace = True)\n",
    "            file_csv.replace(to_replace =\"5.20E-\",\n",
    "                 value = \"0.000\",\n",
    "                  inplace = True)\n",
    "            file_csv.replace(to_replace =\"9.33E-\",\n",
    "                 value = \"0.000\",\n",
    "                  inplace = True)\n",
    "            file_csv.replace(to_replace =\"4.31E-\",\n",
    "                 value = \"0.000\",\n",
    "                  inplace = True)\n",
    "            file_csv.replace(to_replace =\"2.64E-\",\n",
    "                 value = \"0.000\",\n",
    "                  inplace = True)\n",
    "            file_csv.replace(to_replace =\"3.23E-\",\n",
    "                 value = \"0.000\",\n",
    "                  inplace = True)\n",
    "            file_csv.replace(to_replace =\"5.82E-\",\n",
    "                 value = \"0.000\",\n",
    "                  inplace = True)\n",
    "            file_csv.replace(to_replace =\"6.11E-\",\n",
    "                 value = \"0.000\",\n",
    "                  inplace = True)\n",
    "            file_csv.replace(to_replace =\"9.59E-\",\n",
    "                 value = \"0.000\",\n",
    "                  inplace = True)\n",
    "            # print(file_csv.loc[val,'P_Score'])\n",
    "            p_score = float(file_csv.loc[val,'P_Score'])\n",
    "            # print(p_score)\n",
    "            if (p_score!=0 and e_score!=0):\n",
    "                if e_score>=0.6:\n",
    "                    file_csv.loc[val, 'Gene_essentaility'] = 'E'\n",
    "                else:\n",
    "                    file_csv.loc[val, 'Gene_essentaility'] = 'NE'\n",
    "            else:\n",
    "                if (p_score>=0.03 or e_score>=0.6):\n",
    "                    file_csv.loc[val, 'Gene_essentaility'] = 'E'\n",
    "                else:\n",
    "                    file_csv.loc[val, 'Gene_essentaility'] = 'NE'\n",
    "    #file_csv.to_csv(f)\n",
    "    # !rm /content/results/{organism[i]}/EssentialcodonwFeature.out\n",
    "    !rm {input_path}{filename}\n",
    "    file_csv.to_excel(output_path+supprimer_extension(filename)+'.xlsx', index= None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69kjaER7OUgF",
    "outputId": "34fa825d-1135-4b6a-ae3a-6304eb30a02e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'data'...\n",
      "remote: Enumerating objects: 4647, done.\u001b[K\n",
      "remote: Counting objects: 100% (4647/4647), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1486/1486), done.\u001b[K\n",
      "remote: Total 4647 (delta 3436), reused 4367 (delta 3160), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (4647/4647), 65.83 MiB | 19.77 MiB/s, done.\n",
      "Resolving deltas: 100% (3436/3436), done.\n",
      "Updating files: 100% (4627/4627), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://gitlab.com/Berthoazeye/data.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uCxpmzVNOiz8",
    "outputId": "c13d9ca2-f87d-47b0-8b9b-98c08f6688e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: remote origin1 already exists.\n",
      "Host key verification failed.\n",
      "fatal: Could not read from remote repository.\n",
      "\n",
      "Please make sure you have the correct access rights\n",
      "and the repository exists.\n"
     ]
    }
   ],
   "source": [
    "!cd /content/dataLabels\n",
    "\n",
    "# !git config --global user.email \"romeoberthoazeye@gmail.com\"\n",
    "# !git config --global user.name \"berthoazeyeh\"\n",
    "\n",
    "# !git init\n",
    "# !git add .\n",
    "# !git commit -m \"data\"\n",
    "# !git branch -M main\n",
    "!git remote add origin1 git@github.com:berthoazeyeh/EPATHDATAS.git\n",
    "!git push -u origin1 main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tw6dyYDq021y",
    "outputId": "007009d8-6271-49fc-b220-ab99e15a6ed4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "fatal: could not read Username for 'https://github.com': No such device or address\n"
     ]
    }
   ],
   "source": [
    "# !ssh-keygen\n",
    "# !git push --set-upstream origin main\n",
    "\n",
    "# !ls /content/.ssh/id_rsa\n",
    "\n",
    "!git credential-cache exit\n",
    "!git credential-cache store\n",
    "\n",
    "\n",
    "!git branch -M master\n",
    "!git push -u origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "0T0ruIvD1NkK"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def compresser_dossier(source_dir, output_zip):\n",
    "    \"\"\"\n",
    "    Compresser les données d'un dossier en un fichier ZIP.\n",
    "\n",
    "    Args:\n",
    "        source_dir (str): Chemin du dossier source à compresser.\n",
    "        output_zip (str): Chemin du fichier ZIP de sortie.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(source_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                zipf.write(file_path, os.path.relpath(file_path, source_dir))\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "dossier_source = '/content/data'\n",
    "fichier_zip_sortie = '/content/fichier33.zip'\n",
    "\n",
    "compresser_dossier(dossier_source, fichier_zip_sortie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPD0MFf-5Ax6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
